---
title: "Singularität in Sicht!"
date: "2023-01-29T14:08:32+01:00"
tags:
  - "Generde"
  - "Gerante"
keywords:
  - "KI"
  - "ChatGPT"
  - "DALL-E"
  - "Medien"
persons:
  - "Ben"
articleImage:
  src: "dall-e_singularity.jpg"
  width: 1024
  height: 1024
  alt: "atomic explosion above the ocean with birds in the sky and computers in the water comic style"
---

„Thunderbolt and lightning, very very frightning!“[^1]

Ich kann mich noch ausgezeichnet erinnern, wie es damals war, als Steve Jobs das iPad ankündigte. Und wie in der, seinerzeit von Zukunftsängsten arg gebeutelten, Zeitungsindustrie[^2] ein wahrer Boom ausbrach, vorherzusagen, welche revolutionären Auswirkungen das Angekündigte auf dieselbe haben werde. Nichts weniger als die Rettung des gedruckten Wortes wurde erwartet. Der, zum Teil selbst, herbeigeschriebene Tod der Zeitung auf Papier, sollte von dem Geist aus der Maschine abgewendet werden, in Form von Apps, für die Leserinnen und Leser endlich wieder mit Freuden bezahlen würden. Diese Zeit hat großen Einfluss auf meine Karriere gehabt. Nicht nur war sie [Basis einer satirischen Artikelserie](https://couchblog.de/blog/2022/05/18/20-jahre-couchblog-wochenschau/) in diesem Blog, nein, ich habe auch an mehreren solcher wunderverheissenden Apps mitgewirkt und neben einem gigantischen Flop dabei sogar einiges mit erreicht. Nur gerettet wurde das gedruckte Wort dabei eher nicht oder lediglich mittelbar, als Teil einer größeren Strategie, die da geheißen haben könnte, wir werfen möglichst viel Dreck an die Wand und das, was davon kleben bleibt, das nehmen wir dann.

2023 nun steht das gedruckte Wort erneut [am Scheideweg](https://youtu.be/wgWjUCSVH5g), die Dinge wiederholen sich. Und wieder zieht eine neue Technologie am Horizont auf und wieder wird sie angefüllt mit Erwartungen darüber, was sie für uns tun kann. Diesmal zog sich der Prozess allerdings deutlich länger hin. Quasi über Jahrzehnte. Zunächst war es Science-Fiction-Literatur, die vorhersagte, was passieren wird, wenn die Maschinen anfangen zu denken. Seit [AlphaGo jedoch Lee Sedol besiegte](https://de.wikipedia.org/wiki/AlphaGo_gegen_Lee_Sedol), traten wir in eine neue Phase ein: _machine und deep learning_ waren von diesem Moment an als künstliche Intelligenz in allem zu finden, wurden in jedes Produkt eingebaut, das nicht bei drei auf dem Baum war und wenn es nur in die Werbung für dasselbe war. Seit aber inzwischen jedoch [DALL-E](https://de.wikipedia.org/wiki/DALL-E) Bilder für uns malt und [ChatGPT](https://de.wikipedia.org/wiki/ChatGPT) Texte für uns schreibt, ist gewissermaßen kein Halten mehr.

> AI-generated content **can be** of higher quality than content created by humans, due to the fact that AI models are able to learn from a large amount of data and identify patterns that humans may not be able to see. This **can** result in more accurate and informative content.
> — Thomas H. Davenport and Nitin Mittal[^3]

Wir müssen mit allem rechnen, alles kann passieren, sogar die Rettung des gedruckten Wortes. Oder eben, dass eine KI in der Zukunft einen Kampfroboter baut und ihn durch die Zeit schickt, um die Mutter desjenigen Mannes zu töten, der einen Kampfroboter hacken wird, der die KI umbringen werden wird. Oder so. Bei LargeLanguageModels (LLM) geht es um Vorhersagen, wie wir gleich noch lernen werden, und als ginge es darum, ist das Netz plötzlich voll mit Vorhersagen, was „KI“ für uns tun können wird, oder wie sie uns zerstört. Google hat 12.000 Leute entlassen, [aus Angst vor ChatGPT](https://www.theguardian.com/commentisfree/2023/jan/28/why-has-alphabet-hit-the-panic-button-only-google-can-answer-that-question)? Aber warum hat dann Microsoft, die in großem Stil an OpenAI, der Firma dahinter, beteiligt ist, Arbeitskräfte in gleicher Größenordnung auf die Straße gesetzt? Oder bereitet das ganze Silicon Valley sich darauf vor, ganz ganz fett auf den KI-Zug aufzuspringen?

Donner. Blitz. Vielleicht wurde schon dieser Text von einer AI verfasst. Würden wir das merken? Und wenn ja, würde das etwas ändern?

Aber was machen Programme wie ChatGPT oder DALL-E eigentlich? Sie fallen in den Bereich generativer KI (generative AI) und sind eng verwandt mit der vorhersagenden KI (predictive KI). Es hat sehr lange gedauert, ihren Vorgänger mit _deep learning_ und _pattern recognition_ beizubringen, Bilder von Katzen und Hunden zu unterscheiden.

> What’s been different in the last five years is that, because of a new technology called transformers and other related technologies, computers have gotten good at reversing the perception task of identifying a cat or dog. This means that, given text prompts, they can actually generate a plausible image of a cat or a dog or even fanciful things like an astronaut riding a horse. The same thing is happening with text: Not only are models taking a piece of text and classifying it, but given a prompt, these models can essentially run classification in reverse and produce plausible text that might fit into the category given.
> — [Arvind Narayanan](https://www.cs.princeton.edu/~arvindn/)[^4]

[Das Ganze ist eine Art Party Trick](https://fedi.simonwillison.net/@simon/109769667710484189). ChatGPT ist ungeheuer belesen, hat also für uns unvorstellbare Massen von Texten konsumiert. Aber nicht verstanden in dem Sinne, wie wir Verstehen definieren würden. Vielmehr hat es in all diesen Texten Muster ausgemacht. Das Programm macht nun Vorhersagen über das nächste zu schreibende Wort, aus dem vorigen Kontext und den vorgegebenen Fragen heraus. Wenn das groß genug skaliert wird, kann das den Eindruck von Intelligenz erwecken. ChatGPT kann einen Text im Ton von William Shakespeare schreiben, weil es weiß, _wie_ Shakespeare schrieb, gleichzeitig aber keine Ahnung davon haben, dass Shakespeare nur im klingonischen Original wirklich zur Geltung kommt.

Das ist nur die Simulation von Intelligenz.

Das käme dem entgegen, was heute schon reine Simulation ist. Wie Oliver Reichenstein [so schön schreibt](https://ia.net/topics/the-end-of-writing-ia-on-ai). Und Ben für uns so schön übersetzt.

> ChatGPT ist in dem, was es gut kann deshalb so gut, weil das, was es simuliert selber schon Simulationen sind. Simulationen von Schule, Lernen, Wissen und Arbeit. Wir tun über weiteste Strecken nur so, als würden wir etwas lernen, als würden wir Wissen haben, Wissen wirklich weitergeben wollen, wirklich arbeiten.
> — Benjamin Birkenhake[^5]

Das ist keine Intelligenz im Sinne der Definition. Die [Singularität](https://de.wikipedia.org/wiki/Technologische_Singularit%C3%A4t) ist noch weit. Aber vielleicht ändern wir in Zukunft die Definition? Wir wissen es nicht. Noch nicht. Blitz! Donner!

Titelbild: Ein von DALL-E errechnetes Bild zu: „atomic explosion above the ocean with birds in the sky and computers in the water comic style”

[^1]: Zum Schreiben dieses Textes habe ich über Kopfhörer die Geräuschkulisse „Distant Thunderstorm“ der App „Dark Noise“ gelauscht, was ich auch dringend beim Lesen dieses Textes zur Erhöhung des Effekts empfehlen möchte.

[^2]: zumindest des von mir beobachteten Teils derselben

[^3]: Havard Business Review: [How Generative AI Is Changing Creative Work](https://hbr.org/2022/11/how-generative-ai-is-changing-creative-work)

[^4]: The Markup: [Decoding the Hype About AI](https://themarkup.org/hello-world/2023/01/28/decoding-the-hype-about-ai)

[^5]: Anmut und Demut: [simulation of simulations](https://anmutunddemut.de/2023/01/27/simulation-of-simulations.html)
